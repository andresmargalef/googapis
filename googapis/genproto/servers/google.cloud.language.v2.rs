// This file is @generated by prost-build.
/// Represents the input to API methods.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Document {
    /// Required. If the type is not set or is `TYPE_UNSPECIFIED`,
    /// returns an `INVALID_ARGUMENT` error.
    #[prost(enumeration = "document::Type", tag = "1")]
    pub r#type: i32,
    /// Optional. The language of the document (if not specified, the language is
    /// automatically detected). Both ISO and BCP-47 language codes are
    /// accepted.<br>
    /// [Language
    /// Support](<https://cloud.google.com/natural-language/docs/languages>) lists
    /// currently supported languages for each API method. If the language (either
    /// specified by the caller or automatically detected) is not supported by the
    /// called API method, an `INVALID_ARGUMENT` error is returned.
    #[prost(string, tag = "4")]
    pub language_code: ::prost::alloc::string::String,
    /// The source of the document: a string containing the content or a
    /// Google Cloud Storage URI.
    #[prost(oneof = "document::Source", tags = "2, 3")]
    pub source: ::core::option::Option<document::Source>,
}
/// Nested message and enum types in `Document`.
pub mod document {
    /// The document types enum.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum Type {
        /// The content type is not specified.
        Unspecified = 0,
        /// Plain text
        PlainText = 1,
        /// HTML
        Html = 2,
    }
    impl Type {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Type::Unspecified => "TYPE_UNSPECIFIED",
                Type::PlainText => "PLAIN_TEXT",
                Type::Html => "HTML",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "TYPE_UNSPECIFIED" => Some(Self::Unspecified),
                "PLAIN_TEXT" => Some(Self::PlainText),
                "HTML" => Some(Self::Html),
                _ => None,
            }
        }
    }
    /// The source of the document: a string containing the content or a
    /// Google Cloud Storage URI.
    #[allow(clippy::derive_partial_eq_without_eq)]
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Source {
        /// The content of the input in string format.
        /// Cloud audit logging exempt since it is based on user data.
        #[prost(string, tag = "2")]
        Content(::prost::alloc::string::String),
        /// The Google Cloud Storage URI where the file content is located.
        /// This URI must be of the form: gs://bucket_name/object_name. For more
        /// details, see <https://cloud.google.com/storage/docs/reference-uris.>
        /// NOTE: Cloud Storage object versioning is not supported.
        #[prost(string, tag = "3")]
        GcsContentUri(::prost::alloc::string::String),
    }
}
/// Represents a sentence in the input document.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Sentence {
    /// The sentence text.
    #[prost(message, optional, tag = "1")]
    pub text: ::core::option::Option<TextSpan>,
    /// For calls to [AnalyzeSentiment][] or if
    /// [AnnotateTextRequest.Features.extract_document_sentiment][google.cloud.language.v2.AnnotateTextRequest.Features.extract_document_sentiment]
    /// is set to true, this field will contain the sentiment for the sentence.
    #[prost(message, optional, tag = "2")]
    pub sentiment: ::core::option::Option<Sentiment>,
}
/// Represents a phrase in the text that is a known entity, such as
/// a person, an organization, or location. The API associates information, such
/// as probability and mentions, with entities.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Entity {
    /// The representative name for the entity.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// The entity type.
    #[prost(enumeration = "entity::Type", tag = "2")]
    pub r#type: i32,
    /// Metadata associated with the entity.
    ///
    /// For most entity types, the metadata is a Wikipedia URL (`wikipedia_url`)
    /// and Knowledge Graph MID (`mid`), if they are available. For the metadata
    /// associated with other entity types, see the Type table below.
    #[prost(map = "string, string", tag = "3")]
    pub metadata: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        ::prost::alloc::string::String,
    >,
    /// The mentions of this entity in the input document. The API currently
    /// supports proper noun mentions.
    #[prost(message, repeated, tag = "5")]
    pub mentions: ::prost::alloc::vec::Vec<EntityMention>,
    /// For calls to [AnalyzeEntitySentiment][] or if
    /// [AnnotateTextRequest.Features.extract_entity_sentiment][google.cloud.language.v2.AnnotateTextRequest.Features.extract_entity_sentiment]
    /// is set to true, this field will contain the aggregate sentiment expressed
    /// for this entity in the provided document.
    #[prost(message, optional, tag = "6")]
    pub sentiment: ::core::option::Option<Sentiment>,
}
/// Nested message and enum types in `Entity`.
pub mod entity {
    /// The type of the entity. For most entity types, the associated metadata is a
    /// Wikipedia URL (`wikipedia_url`) and Knowledge Graph MID (`mid`). The table
    /// below lists the associated fields for entities that have different
    /// metadata.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum Type {
        /// Unknown
        Unknown = 0,
        /// Person
        Person = 1,
        /// Location
        Location = 2,
        /// Organization
        Organization = 3,
        /// Event
        Event = 4,
        /// Artwork
        WorkOfArt = 5,
        /// Consumer product
        ConsumerGood = 6,
        /// Other types of entities
        Other = 7,
        /// Phone number
        ///
        /// The metadata lists the phone number, formatted according to local
        /// convention, plus whichever additional elements appear in the text:
        ///
        /// * `number` - the actual number, broken down into sections as per local
        /// convention
        /// * `national_prefix` - country code, if detected
        /// * `area_code` - region or area code, if detected
        /// * `extension` - phone extension (to be dialed after connection), if
        /// detected
        PhoneNumber = 9,
        /// Address
        ///
        /// The metadata identifies the street number and locality plus whichever
        /// additional elements appear in the text:
        ///
        /// * `street_number` - street number
        /// * `locality` - city or town
        /// * `street_name` - street/route name, if detected
        /// * `postal_code` - postal code, if detected
        /// * `country` - country, if detected<
        /// * `broad_region` - administrative area, such as the state, if detected
        /// * `narrow_region` - smaller administrative area, such as county, if
        /// detected
        /// * `sublocality` - used in Asian addresses to demark a district within a
        /// city, if detected
        Address = 10,
        /// Date
        ///
        /// The metadata identifies the components of the date:
        ///
        /// * `year` - four digit year, if detected
        /// * `month` - two digit month number, if detected
        /// * `day` - two digit day number, if detected
        Date = 11,
        /// Number
        ///
        /// The metadata is the number itself.
        Number = 12,
        /// Price
        ///
        /// The metadata identifies the `value` and `currency`.
        Price = 13,
    }
    impl Type {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Type::Unknown => "UNKNOWN",
                Type::Person => "PERSON",
                Type::Location => "LOCATION",
                Type::Organization => "ORGANIZATION",
                Type::Event => "EVENT",
                Type::WorkOfArt => "WORK_OF_ART",
                Type::ConsumerGood => "CONSUMER_GOOD",
                Type::Other => "OTHER",
                Type::PhoneNumber => "PHONE_NUMBER",
                Type::Address => "ADDRESS",
                Type::Date => "DATE",
                Type::Number => "NUMBER",
                Type::Price => "PRICE",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "UNKNOWN" => Some(Self::Unknown),
                "PERSON" => Some(Self::Person),
                "LOCATION" => Some(Self::Location),
                "ORGANIZATION" => Some(Self::Organization),
                "EVENT" => Some(Self::Event),
                "WORK_OF_ART" => Some(Self::WorkOfArt),
                "CONSUMER_GOOD" => Some(Self::ConsumerGood),
                "OTHER" => Some(Self::Other),
                "PHONE_NUMBER" => Some(Self::PhoneNumber),
                "ADDRESS" => Some(Self::Address),
                "DATE" => Some(Self::Date),
                "NUMBER" => Some(Self::Number),
                "PRICE" => Some(Self::Price),
                _ => None,
            }
        }
    }
}
/// Represents the feeling associated with the entire text or entities in
/// the text.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Sentiment {
    /// A non-negative number in the [0, +inf) range, which represents
    /// the absolute magnitude of sentiment regardless of score (positive or
    /// negative).
    #[prost(float, tag = "1")]
    pub magnitude: f32,
    /// Sentiment score between -1.0 (negative sentiment) and 1.0
    /// (positive sentiment).
    #[prost(float, tag = "2")]
    pub score: f32,
}
/// Represents a mention for an entity in the text. Currently, proper noun
/// mentions are supported.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct EntityMention {
    /// The mention text.
    #[prost(message, optional, tag = "1")]
    pub text: ::core::option::Option<TextSpan>,
    /// The type of the entity mention.
    #[prost(enumeration = "entity_mention::Type", tag = "2")]
    pub r#type: i32,
    /// For calls to [AnalyzeEntitySentiment][] or if
    /// [AnnotateTextRequest.Features.extract_entity_sentiment][google.cloud.language.v2.AnnotateTextRequest.Features.extract_entity_sentiment]
    /// is set to true, this field will contain the sentiment expressed for this
    /// mention of the entity in the provided document.
    #[prost(message, optional, tag = "3")]
    pub sentiment: ::core::option::Option<Sentiment>,
    /// Probability score associated with the entity.
    ///
    /// The score shows the probability of the entity mention being the entity
    /// type. The score is in (0, 1] range.
    #[prost(float, tag = "4")]
    pub probability: f32,
}
/// Nested message and enum types in `EntityMention`.
pub mod entity_mention {
    /// The supported types of mentions.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum Type {
        /// Unknown
        Unknown = 0,
        /// Proper name
        Proper = 1,
        /// Common noun (or noun compound)
        Common = 2,
    }
    impl Type {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Type::Unknown => "TYPE_UNKNOWN",
                Type::Proper => "PROPER",
                Type::Common => "COMMON",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "TYPE_UNKNOWN" => Some(Self::Unknown),
                "PROPER" => Some(Self::Proper),
                "COMMON" => Some(Self::Common),
                _ => None,
            }
        }
    }
}
/// Represents a text span in the input document.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct TextSpan {
    /// The content of the text span, which is a substring of the document.
    #[prost(string, tag = "1")]
    pub content: ::prost::alloc::string::String,
    /// The API calculates the beginning offset of the content in the original
    /// document according to the
    /// [EncodingType][google.cloud.language.v2.EncodingType] specified in the API
    /// request.
    #[prost(int32, tag = "2")]
    pub begin_offset: i32,
}
/// Represents a category returned from the text classifier.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ClassificationCategory {
    /// The name of the category representing the document.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// The classifier's confidence of the category. Number represents how certain
    /// the classifier is that this category represents the given text.
    #[prost(float, tag = "2")]
    pub confidence: f32,
}
/// The sentiment analysis request message.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct AnalyzeSentimentRequest {
    /// Required. Input document.
    #[prost(message, optional, tag = "1")]
    pub document: ::core::option::Option<Document>,
    /// The encoding type used by the API to calculate sentence offsets.
    #[prost(enumeration = "EncodingType", tag = "2")]
    pub encoding_type: i32,
}
/// The sentiment analysis response message.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct AnalyzeSentimentResponse {
    /// The overall sentiment of the input document.
    #[prost(message, optional, tag = "1")]
    pub document_sentiment: ::core::option::Option<Sentiment>,
    /// The language of the text, which will be the same as the language specified
    /// in the request or, if not specified, the automatically-detected language.
    /// See [Document.language][] field for more details.
    #[prost(string, tag = "2")]
    pub language_code: ::prost::alloc::string::String,
    /// The sentiment for all the sentences in the document.
    #[prost(message, repeated, tag = "3")]
    pub sentences: ::prost::alloc::vec::Vec<Sentence>,
    /// Whether the language is officially supported. The API may still return a
    /// response when the language is not supported, but it is on a best effort
    /// basis.
    #[prost(bool, tag = "4")]
    pub language_supported: bool,
}
/// The entity analysis request message.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct AnalyzeEntitiesRequest {
    /// Required. Input document.
    #[prost(message, optional, tag = "1")]
    pub document: ::core::option::Option<Document>,
    /// The encoding type used by the API to calculate offsets.
    #[prost(enumeration = "EncodingType", tag = "2")]
    pub encoding_type: i32,
}
/// The entity analysis response message.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct AnalyzeEntitiesResponse {
    /// The recognized entities in the input document.
    #[prost(message, repeated, tag = "1")]
    pub entities: ::prost::alloc::vec::Vec<Entity>,
    /// The language of the text, which will be the same as the language specified
    /// in the request or, if not specified, the automatically-detected language.
    /// See [Document.language][] field for more details.
    #[prost(string, tag = "2")]
    pub language_code: ::prost::alloc::string::String,
    /// Whether the language is officially supported. The API may still return a
    /// response when the language is not supported, but it is on a best effort
    /// basis.
    #[prost(bool, tag = "3")]
    pub language_supported: bool,
}
/// The document classification request message.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ClassifyTextRequest {
    /// Required. Input document.
    #[prost(message, optional, tag = "1")]
    pub document: ::core::option::Option<Document>,
}
/// The document classification response message.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ClassifyTextResponse {
    /// Categories representing the input document.
    #[prost(message, repeated, tag = "1")]
    pub categories: ::prost::alloc::vec::Vec<ClassificationCategory>,
    /// The language of the text, which will be the same as the language specified
    /// in the request or, if not specified, the automatically-detected language.
    /// See [Document.language][] field for more details.
    #[prost(string, tag = "2")]
    pub language_code: ::prost::alloc::string::String,
    /// Whether the language is officially supported. The API may still return a
    /// response when the language is not supported, but it is on a best effort
    /// basis.
    #[prost(bool, tag = "3")]
    pub language_supported: bool,
}
/// The document moderation request message.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ModerateTextRequest {
    /// Required. Input document.
    #[prost(message, optional, tag = "1")]
    pub document: ::core::option::Option<Document>,
}
/// The document moderation response message.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ModerateTextResponse {
    /// Harmful and sensitive categories representing the input document.
    #[prost(message, repeated, tag = "1")]
    pub moderation_categories: ::prost::alloc::vec::Vec<ClassificationCategory>,
    /// The language of the text, which will be the same as the language specified
    /// in the request or, if not specified, the automatically-detected language.
    /// See [Document.language][] field for more details.
    #[prost(string, tag = "2")]
    pub language_code: ::prost::alloc::string::String,
    /// Whether the language is officially supported. The API may still return a
    /// response when the language is not supported, but it is on a best effort
    /// basis.
    #[prost(bool, tag = "3")]
    pub language_supported: bool,
}
/// The request message for the text annotation API, which can perform multiple
/// analysis types in one call.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct AnnotateTextRequest {
    /// Required. Input document.
    #[prost(message, optional, tag = "1")]
    pub document: ::core::option::Option<Document>,
    /// Required. The enabled features.
    #[prost(message, optional, tag = "2")]
    pub features: ::core::option::Option<annotate_text_request::Features>,
    /// The encoding type used by the API to calculate offsets.
    #[prost(enumeration = "EncodingType", tag = "3")]
    pub encoding_type: i32,
}
/// Nested message and enum types in `AnnotateTextRequest`.
pub mod annotate_text_request {
    /// All available features.
    /// Setting each one to true will enable that specific analysis for the input.
    #[allow(clippy::derive_partial_eq_without_eq)]
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct Features {
        /// Optional. Extract entities.
        #[prost(bool, tag = "1")]
        pub extract_entities: bool,
        /// Optional. Extract document-level sentiment.
        #[prost(bool, tag = "2")]
        pub extract_document_sentiment: bool,
        /// Optional. Classify the full document into categories.
        #[prost(bool, tag = "4")]
        pub classify_text: bool,
        /// Optional. Moderate the document for harmful and sensitive categories.
        #[prost(bool, tag = "5")]
        pub moderate_text: bool,
    }
}
/// The text annotations response message.
#[allow(clippy::derive_partial_eq_without_eq)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct AnnotateTextResponse {
    /// Sentences in the input document. Populated if the user enables
    /// [AnnotateTextRequest.Features.extract_document_sentiment][google.cloud.language.v2.AnnotateTextRequest.Features.extract_document_sentiment].
    #[prost(message, repeated, tag = "1")]
    pub sentences: ::prost::alloc::vec::Vec<Sentence>,
    /// Entities, along with their semantic information, in the input document.
    /// Populated if the user enables
    /// [AnnotateTextRequest.Features.extract_entities][google.cloud.language.v2.AnnotateTextRequest.Features.extract_entities]
    /// or
    /// [AnnotateTextRequest.Features.extract_entity_sentiment][google.cloud.language.v2.AnnotateTextRequest.Features.extract_entity_sentiment].
    #[prost(message, repeated, tag = "2")]
    pub entities: ::prost::alloc::vec::Vec<Entity>,
    /// The overall sentiment for the document. Populated if the user enables
    /// [AnnotateTextRequest.Features.extract_document_sentiment][google.cloud.language.v2.AnnotateTextRequest.Features.extract_document_sentiment].
    #[prost(message, optional, tag = "3")]
    pub document_sentiment: ::core::option::Option<Sentiment>,
    /// The language of the text, which will be the same as the language specified
    /// in the request or, if not specified, the automatically-detected language.
    /// See [Document.language][] field for more details.
    #[prost(string, tag = "4")]
    pub language_code: ::prost::alloc::string::String,
    /// Categories identified in the input document.
    #[prost(message, repeated, tag = "5")]
    pub categories: ::prost::alloc::vec::Vec<ClassificationCategory>,
    /// Harmful and sensitive categories identified in the input document.
    #[prost(message, repeated, tag = "6")]
    pub moderation_categories: ::prost::alloc::vec::Vec<ClassificationCategory>,
    /// Whether the language is officially supported by all requested features.
    /// The API may still return a response when the language is not supported, but
    /// it is on a best effort basis.
    #[prost(bool, tag = "7")]
    pub language_supported: bool,
}
/// Represents the text encoding that the caller uses to process the output.
/// Providing an `EncodingType` is recommended because the API provides the
/// beginning offsets for various outputs, such as tokens and mentions, and
/// languages that natively use different text encodings may access offsets
/// differently.
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum EncodingType {
    /// If `EncodingType` is not specified, encoding-dependent information (such as
    /// `begin_offset`) will be set at `-1`.
    None = 0,
    /// Encoding-dependent information (such as `begin_offset`) is calculated based
    /// on the UTF-8 encoding of the input. C++ and Go are examples of languages
    /// that use this encoding natively.
    Utf8 = 1,
    /// Encoding-dependent information (such as `begin_offset`) is calculated based
    /// on the UTF-16 encoding of the input. Java and JavaScript are examples of
    /// languages that use this encoding natively.
    Utf16 = 2,
    /// Encoding-dependent information (such as `begin_offset`) is calculated based
    /// on the UTF-32 encoding of the input. Python is an example of a language
    /// that uses this encoding natively.
    Utf32 = 3,
}
impl EncodingType {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            EncodingType::None => "NONE",
            EncodingType::Utf8 => "UTF8",
            EncodingType::Utf16 => "UTF16",
            EncodingType::Utf32 => "UTF32",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "NONE" => Some(Self::None),
            "UTF8" => Some(Self::Utf8),
            "UTF16" => Some(Self::Utf16),
            "UTF32" => Some(Self::Utf32),
            _ => None,
        }
    }
}
/// Generated server implementations.
pub mod language_service_server {
    #![allow(unused_variables, dead_code, missing_docs, clippy::let_unit_value)]
    use tonic::codegen::*;
    /// Generated trait containing gRPC methods that should be implemented for use with LanguageServiceServer.
    #[async_trait]
    pub trait LanguageService: Send + Sync + 'static {
        /// Analyzes the sentiment of the provided text.
        async fn analyze_sentiment(
            &self,
            request: tonic::Request<super::AnalyzeSentimentRequest>,
        ) -> std::result::Result<
            tonic::Response<super::AnalyzeSentimentResponse>,
            tonic::Status,
        >;
        /// Finds named entities (currently proper names and common nouns) in the text
        /// along with entity types, probability, mentions for each entity, and
        /// other properties.
        async fn analyze_entities(
            &self,
            request: tonic::Request<super::AnalyzeEntitiesRequest>,
        ) -> std::result::Result<
            tonic::Response<super::AnalyzeEntitiesResponse>,
            tonic::Status,
        >;
        /// Classifies a document into categories.
        async fn classify_text(
            &self,
            request: tonic::Request<super::ClassifyTextRequest>,
        ) -> std::result::Result<
            tonic::Response<super::ClassifyTextResponse>,
            tonic::Status,
        >;
        /// Moderates a document for harmful and sensitive categories.
        async fn moderate_text(
            &self,
            request: tonic::Request<super::ModerateTextRequest>,
        ) -> std::result::Result<
            tonic::Response<super::ModerateTextResponse>,
            tonic::Status,
        >;
        /// A convenience method that provides all features in one call.
        async fn annotate_text(
            &self,
            request: tonic::Request<super::AnnotateTextRequest>,
        ) -> std::result::Result<
            tonic::Response<super::AnnotateTextResponse>,
            tonic::Status,
        >;
    }
    /// Provides text analysis operations such as sentiment analysis and entity
    /// recognition.
    #[derive(Debug)]
    pub struct LanguageServiceServer<T: LanguageService> {
        inner: _Inner<T>,
        accept_compression_encodings: EnabledCompressionEncodings,
        send_compression_encodings: EnabledCompressionEncodings,
        max_decoding_message_size: Option<usize>,
        max_encoding_message_size: Option<usize>,
    }
    struct _Inner<T>(Arc<T>);
    impl<T: LanguageService> LanguageServiceServer<T> {
        pub fn new(inner: T) -> Self {
            Self::from_arc(Arc::new(inner))
        }
        pub fn from_arc(inner: Arc<T>) -> Self {
            let inner = _Inner(inner);
            Self {
                inner,
                accept_compression_encodings: Default::default(),
                send_compression_encodings: Default::default(),
                max_decoding_message_size: None,
                max_encoding_message_size: None,
            }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> InterceptedService<Self, F>
        where
            F: tonic::service::Interceptor,
        {
            InterceptedService::new(Self::new(inner), interceptor)
        }
        /// Enable decompressing requests with the given encoding.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.accept_compression_encodings.enable(encoding);
            self
        }
        /// Compress responses with the given encoding, if the client supports it.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.send_compression_encodings.enable(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.max_decoding_message_size = Some(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.max_encoding_message_size = Some(limit);
            self
        }
    }
    impl<T, B> tonic::codegen::Service<http::Request<B>> for LanguageServiceServer<T>
    where
        T: LanguageService,
        B: Body + Send + 'static,
        B::Error: Into<StdError> + Send + 'static,
    {
        type Response = http::Response<tonic::body::BoxBody>;
        type Error = std::convert::Infallible;
        type Future = BoxFuture<Self::Response, Self::Error>;
        fn poll_ready(
            &mut self,
            _cx: &mut Context<'_>,
        ) -> Poll<std::result::Result<(), Self::Error>> {
            Poll::Ready(Ok(()))
        }
        fn call(&mut self, req: http::Request<B>) -> Self::Future {
            let inner = self.inner.clone();
            match req.uri().path() {
                "/google.cloud.language.v2.LanguageService/AnalyzeSentiment" => {
                    #[allow(non_camel_case_types)]
                    struct AnalyzeSentimentSvc<T: LanguageService>(pub Arc<T>);
                    impl<
                        T: LanguageService,
                    > tonic::server::UnaryService<super::AnalyzeSentimentRequest>
                    for AnalyzeSentimentSvc<T> {
                        type Response = super::AnalyzeSentimentResponse;
                        type Future = BoxFuture<
                            tonic::Response<Self::Response>,
                            tonic::Status,
                        >;
                        fn call(
                            &mut self,
                            request: tonic::Request<super::AnalyzeSentimentRequest>,
                        ) -> Self::Future {
                            let inner = Arc::clone(&self.0);
                            let fut = async move {
                                <T as LanguageService>::analyze_sentiment(&inner, request)
                                    .await
                            };
                            Box::pin(fut)
                        }
                    }
                    let accept_compression_encodings = self.accept_compression_encodings;
                    let send_compression_encodings = self.send_compression_encodings;
                    let max_decoding_message_size = self.max_decoding_message_size;
                    let max_encoding_message_size = self.max_encoding_message_size;
                    let inner = self.inner.clone();
                    let fut = async move {
                        let inner = inner.0;
                        let method = AnalyzeSentimentSvc(inner);
                        let codec = tonic::codec::ProstCodec::default();
                        let mut grpc = tonic::server::Grpc::new(codec)
                            .apply_compression_config(
                                accept_compression_encodings,
                                send_compression_encodings,
                            )
                            .apply_max_message_size_config(
                                max_decoding_message_size,
                                max_encoding_message_size,
                            );
                        let res = grpc.unary(method, req).await;
                        Ok(res)
                    };
                    Box::pin(fut)
                }
                "/google.cloud.language.v2.LanguageService/AnalyzeEntities" => {
                    #[allow(non_camel_case_types)]
                    struct AnalyzeEntitiesSvc<T: LanguageService>(pub Arc<T>);
                    impl<
                        T: LanguageService,
                    > tonic::server::UnaryService<super::AnalyzeEntitiesRequest>
                    for AnalyzeEntitiesSvc<T> {
                        type Response = super::AnalyzeEntitiesResponse;
                        type Future = BoxFuture<
                            tonic::Response<Self::Response>,
                            tonic::Status,
                        >;
                        fn call(
                            &mut self,
                            request: tonic::Request<super::AnalyzeEntitiesRequest>,
                        ) -> Self::Future {
                            let inner = Arc::clone(&self.0);
                            let fut = async move {
                                <T as LanguageService>::analyze_entities(&inner, request)
                                    .await
                            };
                            Box::pin(fut)
                        }
                    }
                    let accept_compression_encodings = self.accept_compression_encodings;
                    let send_compression_encodings = self.send_compression_encodings;
                    let max_decoding_message_size = self.max_decoding_message_size;
                    let max_encoding_message_size = self.max_encoding_message_size;
                    let inner = self.inner.clone();
                    let fut = async move {
                        let inner = inner.0;
                        let method = AnalyzeEntitiesSvc(inner);
                        let codec = tonic::codec::ProstCodec::default();
                        let mut grpc = tonic::server::Grpc::new(codec)
                            .apply_compression_config(
                                accept_compression_encodings,
                                send_compression_encodings,
                            )
                            .apply_max_message_size_config(
                                max_decoding_message_size,
                                max_encoding_message_size,
                            );
                        let res = grpc.unary(method, req).await;
                        Ok(res)
                    };
                    Box::pin(fut)
                }
                "/google.cloud.language.v2.LanguageService/ClassifyText" => {
                    #[allow(non_camel_case_types)]
                    struct ClassifyTextSvc<T: LanguageService>(pub Arc<T>);
                    impl<
                        T: LanguageService,
                    > tonic::server::UnaryService<super::ClassifyTextRequest>
                    for ClassifyTextSvc<T> {
                        type Response = super::ClassifyTextResponse;
                        type Future = BoxFuture<
                            tonic::Response<Self::Response>,
                            tonic::Status,
                        >;
                        fn call(
                            &mut self,
                            request: tonic::Request<super::ClassifyTextRequest>,
                        ) -> Self::Future {
                            let inner = Arc::clone(&self.0);
                            let fut = async move {
                                <T as LanguageService>::classify_text(&inner, request).await
                            };
                            Box::pin(fut)
                        }
                    }
                    let accept_compression_encodings = self.accept_compression_encodings;
                    let send_compression_encodings = self.send_compression_encodings;
                    let max_decoding_message_size = self.max_decoding_message_size;
                    let max_encoding_message_size = self.max_encoding_message_size;
                    let inner = self.inner.clone();
                    let fut = async move {
                        let inner = inner.0;
                        let method = ClassifyTextSvc(inner);
                        let codec = tonic::codec::ProstCodec::default();
                        let mut grpc = tonic::server::Grpc::new(codec)
                            .apply_compression_config(
                                accept_compression_encodings,
                                send_compression_encodings,
                            )
                            .apply_max_message_size_config(
                                max_decoding_message_size,
                                max_encoding_message_size,
                            );
                        let res = grpc.unary(method, req).await;
                        Ok(res)
                    };
                    Box::pin(fut)
                }
                "/google.cloud.language.v2.LanguageService/ModerateText" => {
                    #[allow(non_camel_case_types)]
                    struct ModerateTextSvc<T: LanguageService>(pub Arc<T>);
                    impl<
                        T: LanguageService,
                    > tonic::server::UnaryService<super::ModerateTextRequest>
                    for ModerateTextSvc<T> {
                        type Response = super::ModerateTextResponse;
                        type Future = BoxFuture<
                            tonic::Response<Self::Response>,
                            tonic::Status,
                        >;
                        fn call(
                            &mut self,
                            request: tonic::Request<super::ModerateTextRequest>,
                        ) -> Self::Future {
                            let inner = Arc::clone(&self.0);
                            let fut = async move {
                                <T as LanguageService>::moderate_text(&inner, request).await
                            };
                            Box::pin(fut)
                        }
                    }
                    let accept_compression_encodings = self.accept_compression_encodings;
                    let send_compression_encodings = self.send_compression_encodings;
                    let max_decoding_message_size = self.max_decoding_message_size;
                    let max_encoding_message_size = self.max_encoding_message_size;
                    let inner = self.inner.clone();
                    let fut = async move {
                        let inner = inner.0;
                        let method = ModerateTextSvc(inner);
                        let codec = tonic::codec::ProstCodec::default();
                        let mut grpc = tonic::server::Grpc::new(codec)
                            .apply_compression_config(
                                accept_compression_encodings,
                                send_compression_encodings,
                            )
                            .apply_max_message_size_config(
                                max_decoding_message_size,
                                max_encoding_message_size,
                            );
                        let res = grpc.unary(method, req).await;
                        Ok(res)
                    };
                    Box::pin(fut)
                }
                "/google.cloud.language.v2.LanguageService/AnnotateText" => {
                    #[allow(non_camel_case_types)]
                    struct AnnotateTextSvc<T: LanguageService>(pub Arc<T>);
                    impl<
                        T: LanguageService,
                    > tonic::server::UnaryService<super::AnnotateTextRequest>
                    for AnnotateTextSvc<T> {
                        type Response = super::AnnotateTextResponse;
                        type Future = BoxFuture<
                            tonic::Response<Self::Response>,
                            tonic::Status,
                        >;
                        fn call(
                            &mut self,
                            request: tonic::Request<super::AnnotateTextRequest>,
                        ) -> Self::Future {
                            let inner = Arc::clone(&self.0);
                            let fut = async move {
                                <T as LanguageService>::annotate_text(&inner, request).await
                            };
                            Box::pin(fut)
                        }
                    }
                    let accept_compression_encodings = self.accept_compression_encodings;
                    let send_compression_encodings = self.send_compression_encodings;
                    let max_decoding_message_size = self.max_decoding_message_size;
                    let max_encoding_message_size = self.max_encoding_message_size;
                    let inner = self.inner.clone();
                    let fut = async move {
                        let inner = inner.0;
                        let method = AnnotateTextSvc(inner);
                        let codec = tonic::codec::ProstCodec::default();
                        let mut grpc = tonic::server::Grpc::new(codec)
                            .apply_compression_config(
                                accept_compression_encodings,
                                send_compression_encodings,
                            )
                            .apply_max_message_size_config(
                                max_decoding_message_size,
                                max_encoding_message_size,
                            );
                        let res = grpc.unary(method, req).await;
                        Ok(res)
                    };
                    Box::pin(fut)
                }
                _ => {
                    Box::pin(async move {
                        Ok(
                            http::Response::builder()
                                .status(200)
                                .header("grpc-status", "12")
                                .header("content-type", "application/grpc")
                                .body(empty_body())
                                .unwrap(),
                        )
                    })
                }
            }
        }
    }
    impl<T: LanguageService> Clone for LanguageServiceServer<T> {
        fn clone(&self) -> Self {
            let inner = self.inner.clone();
            Self {
                inner,
                accept_compression_encodings: self.accept_compression_encodings,
                send_compression_encodings: self.send_compression_encodings,
                max_decoding_message_size: self.max_decoding_message_size,
                max_encoding_message_size: self.max_encoding_message_size,
            }
        }
    }
    impl<T: LanguageService> Clone for _Inner<T> {
        fn clone(&self) -> Self {
            Self(Arc::clone(&self.0))
        }
    }
    impl<T: std::fmt::Debug> std::fmt::Debug for _Inner<T> {
        fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
            write!(f, "{:?}", self.0)
        }
    }
    impl<T: LanguageService> tonic::server::NamedService for LanguageServiceServer<T> {
        const NAME: &'static str = "google.cloud.language.v2.LanguageService";
    }
}
